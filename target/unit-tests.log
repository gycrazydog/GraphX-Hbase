15/04/30 17:46:21.544 main INFO SparkContext: Running Spark version 1.3.1
15/04/30 17:46:21.566 main WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 145.94.173.115 instead (on interface wlan0)
15/04/30 17:46:21.566 main WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
15/04/30 17:46:21.951 main WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/04/30 17:46:22.081 main INFO SecurityManager: Changing view acls to: crazydog
15/04/30 17:46:22.082 main INFO SecurityManager: Changing modify acls to: crazydog
15/04/30 17:46:22.082 main INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(crazydog); users with modify permissions: Set(crazydog)
15/04/30 17:46:22.418 sparkDriver-akka.actor.default-dispatcher-5 INFO Slf4jLogger: Slf4jLogger started
15/04/30 17:46:22.489 sparkDriver-akka.actor.default-dispatcher-5 INFO Remoting: Starting remoting
15/04/30 17:46:22.621 sparkDriver-akka.actor.default-dispatcher-5 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@wlan-145-94-173-115.wlan.tudelft.nl:54211]
15/04/30 17:46:22.629 main INFO Utils: Successfully started service 'sparkDriver' on port 54211.
15/04/30 17:46:22.641 main INFO SparkEnv: Registering MapOutputTracker
15/04/30 17:46:22.650 main INFO SparkEnv: Registering BlockManagerMaster
15/04/30 17:46:22.661 main INFO DiskBlockManager: Created local directory at /tmp/spark-4ef0a706-6344-4f4d-a68d-442586b3419c/blockmgr-30f70eed-dd55-4d95-aa73-eb441b0d00a8
15/04/30 17:46:22.664 main INFO MemoryStore: MemoryStore started with capacity 922.6 MB
15/04/30 17:46:22.720 main INFO HttpFileServer: HTTP File server directory is /tmp/spark-9d234d0d-941c-4990-95d3-d1b2446d764c/httpd-ec4086a6-f227-4cfb-91dc-9e4cf1a6a867
15/04/30 17:46:22.723 main INFO HttpServer: Starting HTTP Server
15/04/30 17:46:22.762 main INFO Server: jetty-8.y.z-SNAPSHOT
15/04/30 17:46:22.773 main INFO AbstractConnector: Started SocketConnector@0.0.0.0:37525
15/04/30 17:46:22.773 main INFO Utils: Successfully started service 'HTTP file server' on port 37525.
15/04/30 17:46:22.782 main INFO SparkEnv: Registering OutputCommitCoordinator
15/04/30 17:46:27.955 main INFO Server: jetty-8.y.z-SNAPSHOT
15/04/30 17:46:27.971 main INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
15/04/30 17:46:27.971 main INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/04/30 17:46:27.973 main INFO SparkUI: Started SparkUI at http://wlan-145-94-173-115.wlan.tudelft.nl:4040
15/04/30 17:46:28.043 sparkDriver-akka.actor.default-dispatcher-3 INFO Executor: Starting executor ID <driver> on host localhost
15/04/30 17:46:28.053 sparkDriver-akka.actor.default-dispatcher-3 INFO AkkaUtils: Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@wlan-145-94-173-115.wlan.tudelft.nl:54211/user/HeartbeatReceiver
15/04/30 17:46:28.158 main INFO NettyBlockTransferService: Server created on 42804
15/04/30 17:46:28.159 main INFO BlockManagerMaster: Trying to register BlockManager
15/04/30 17:46:28.160 sparkDriver-akka.actor.default-dispatcher-3 INFO BlockManagerMasterActor: Registering block manager localhost:42804 with 922.6 MB RAM, BlockManagerId(<driver>, localhost, 42804)
15/04/30 17:46:28.162 main INFO BlockManagerMaster: Registered BlockManager
15/04/30 17:46:28.588 main INFO MemoryStore: ensureFreeSpace(117234) called with curMem=0, maxMem=967405731
15/04/30 17:46:28.590 main INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 114.5 KB, free 922.5 MB)
15/04/30 17:46:28.664 main INFO MemoryStore: ensureFreeSpace(34245) called with curMem=117234, maxMem=967405731
15/04/30 17:46:28.664 main INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.4 KB, free 922.4 MB)
15/04/30 17:46:28.666 sparkDriver-akka.actor.default-dispatcher-3 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42804 (size: 33.4 KB, free: 922.6 MB)
15/04/30 17:46:28.666 main INFO BlockManagerMaster: Updated info of block broadcast_0_piece0
15/04/30 17:46:28.668 main INFO SparkContext: Created broadcast 0 from broadcast at HBaseContext.scala:69
15/04/30 17:46:28.669 main INFO MemoryStore: ensureFreeSpace(336) called with curMem=151479, maxMem=967405731
15/04/30 17:46:28.670 main INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 336.0 B, free 922.4 MB)
15/04/30 17:46:28.671 main INFO MemoryStore: ensureFreeSpace(120) called with curMem=151815, maxMem=967405731
15/04/30 17:46:28.671 main INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 120.0 B, free 922.4 MB)
15/04/30 17:46:28.672 sparkDriver-akka.actor.default-dispatcher-3 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42804 (size: 120.0 B, free: 922.6 MB)
15/04/30 17:46:28.672 main INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
15/04/30 17:46:28.673 main INFO SparkContext: Created broadcast 1 from broadcast at HBaseContext.scala:70
15/04/30 17:46:28.718 main INFO SparkContext: Starting job: foreachPartition at HBaseContext.scala:196
15/04/30 17:46:28.727 dag-scheduler-event-loop INFO DAGScheduler: Got job 0 (foreachPartition at HBaseContext.scala:196) with 2 output partitions (allowLocal=false)
15/04/30 17:46:28.728 dag-scheduler-event-loop INFO DAGScheduler: Final stage: Stage 0(foreachPartition at HBaseContext.scala:196)
15/04/30 17:46:28.728 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
15/04/30 17:46:28.732 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
15/04/30 17:46:28.737 dag-scheduler-event-loop INFO DAGScheduler: Submitting Stage 0 (ParallelCollectionRDD[0] at parallelize at SparkOnHbaseTest.scala:25), which has no missing parents
15/04/30 17:46:28.754 dag-scheduler-event-loop INFO MemoryStore: ensureFreeSpace(2072) called with curMem=151935, maxMem=967405731
15/04/30 17:46:28.754 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 2.0 KB, free 922.4 MB)
15/04/30 17:46:28.756 dag-scheduler-event-loop INFO MemoryStore: ensureFreeSpace(1453) called with curMem=154007, maxMem=967405731
15/04/30 17:46:28.757 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1453.0 B, free 922.4 MB)
15/04/30 17:46:28.758 sparkDriver-akka.actor.default-dispatcher-3 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42804 (size: 1453.0 B, free: 922.6 MB)
15/04/30 17:46:28.758 dag-scheduler-event-loop INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
15/04/30 17:46:28.760 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:839
15/04/30 17:46:28.763 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from Stage 0 (ParallelCollectionRDD[0] at parallelize at SparkOnHbaseTest.scala:25)
15/04/30 17:46:28.764 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/04/30 17:46:28.798 sparkDriver-akka.actor.default-dispatcher-3 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1546 bytes)
15/04/30 17:46:28.802 sparkDriver-akka.actor.default-dispatcher-3 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 1621 bytes)
15/04/30 17:46:28.805 Executor task launch worker-1 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/04/30 17:46:28.805 Executor task launch worker-0 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/04/30 17:46:28.834 Executor task launch worker-0 INFO HBaseContext: appliedCredentials:false,credentials:null
15/04/30 17:46:28.834 Executor task launch worker-1 INFO HBaseContext: appliedCredentials:false,credentials:null
15/04/30 17:46:28.881 Executor task launch worker-0 INFO RecoverableZooKeeper: Process identifier=hconnection-0x2052c9cf connecting to ZooKeeper ensemble=localhost:2181
15/04/30 17:46:28.881 Executor task launch worker-1 INFO RecoverableZooKeeper: Process identifier=hconnection-0x1b3f459d connecting to ZooKeeper ensemble=localhost:2181
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:host.name=ubuntu.ubuntu-domain
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:java.version=1.7.0_15
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:java.vendor=Oracle Corporation
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:java.home=/usr/lib/jvm/jdk1.7.0_15/jre
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:java.class.path=/home/crazydog/workspace/Spark test/bin:/home/crazydog/spark-1.3.1-bin-hadoop2.6/lib/spark-assembly-1.3.1-hadoop2.6.0.jar:/home/crazydog/workspace/SparkOnHBase/target/spark-hbase-0.0.2-clabs.jar:/home/crazydog/workspace/SparkOnHBase/target/SparkHBase.jar
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:java.io.tmpdir=/tmp
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:java.compiler=<NA>
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:os.name=Linux
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:os.arch=amd64
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:os.version=3.13.0-32-generic
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:user.name=crazydog
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:user.home=/home/crazydog
15/04/30 17:46:28.885 Executor task launch worker-0 INFO ZooKeeper: Client environment:user.dir=/home/crazydog/workspace/Spark test
15/04/30 17:46:28.886 Executor task launch worker-0 INFO ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x2052c9cf, quorum=localhost:2181, baseZNode=/hbase
15/04/30 17:46:28.886 Executor task launch worker-1 INFO ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x1b3f459d, quorum=localhost:2181, baseZNode=/hbase
15/04/30 17:46:28.897 Executor task launch worker-1-SendThread(localhost:2181) INFO ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/04/30 17:46:28.897 Executor task launch worker-0-SendThread(localhost:2181) INFO ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/04/30 17:46:28.898 Executor task launch worker-1-SendThread(localhost:2181) INFO ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
15/04/30 17:46:28.899 Executor task launch worker-0-SendThread(localhost:2181) INFO ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
15/04/30 17:46:28.955 Executor task launch worker-1-SendThread(localhost:2181) INFO ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14d0af44e8d001d, negotiated timeout = 40000
15/04/30 17:46:29.001 Executor task launch worker-0-SendThread(localhost:2181) INFO ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14d0af44e8d001e, negotiated timeout = 40000
15/04/30 17:46:29.499 Executor task launch worker-0 INFO HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x14d0af44e8d001e
15/04/30 17:46:29.503 Executor task launch worker-1 INFO HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x14d0af44e8d001d
15/04/30 17:46:29.559 Executor task launch worker-0 INFO ZooKeeper: Session: 0x14d0af44e8d001e closed
15/04/30 17:46:29.559 Executor task launch worker-0-EventThread INFO ClientCnxn: EventThread shut down
15/04/30 17:46:29.617 Executor task launch worker-1 INFO ZooKeeper: Session: 0x14d0af44e8d001d closed
15/04/30 17:46:29.617 Executor task launch worker-1-EventThread INFO ClientCnxn: EventThread shut down
15/04/30 17:46:29.666 Executor task launch worker-0 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 620 bytes result sent to driver
15/04/30 17:46:29.670 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 884 ms on localhost (1/2)
15/04/30 17:46:29.718 Executor task launch worker-1 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 620 bytes result sent to driver
15/04/30 17:46:29.719 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 918 ms on localhost (2/2)
15/04/30 17:46:29.720 dag-scheduler-event-loop INFO DAGScheduler: Stage 0 (foreachPartition at HBaseContext.scala:196) finished in 0.949 s
15/04/30 17:46:29.720 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/04/30 17:46:29.727 main INFO DAGScheduler: Job 0 finished: foreachPartition at HBaseContext.scala:196, took 1.009130 s
